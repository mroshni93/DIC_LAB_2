{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Susan now lives in Washington\n",
      " and makes $105000.0\n",
      "Ellen now lives in Texas\n",
      " and makes $78750.0\n"
     ]
    }
   ],
   "source": [
    "#CH3\n",
    "SALARY_RAISE_FACTOR = 0.05\n",
    "STATE_CODE_MAP = {'WA': 'Washington', 'TX': 'Texas'}\n",
    "\n",
    "def update_employee_record(rec):\n",
    "    old_sal = rec['salary']\n",
    "    new_sal = old_sal * (1 + SALARY_RAISE_FACTOR)\n",
    "    rec['salary'] = new_sal\n",
    "    state_code = rec['state_code']\n",
    "    rec['state_name'] = STATE_CODE_MAP[state_code]\n",
    "\n",
    "input_data = [\n",
    "            {'employee_name': 'Susan', 'salary': 100000.0,\n",
    "             'state_code': 'WA'},\n",
    "             {'employee_name': 'Ellen', 'salary': 75000.0,\n",
    "              'state_code': 'TX'},\n",
    "              ]\n",
    "for rec in input_data:\n",
    "    update_employee_record(rec)\n",
    "    name = rec['employee_name']\n",
    "    salary = rec['salary']\n",
    "    state = rec['state_name']\n",
    "    print (name + ' now lives in ' + state)\n",
    "    print (' and makes $' + str(salary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Making data frame from a dictionary\n",
    "# that maps column names to their values\n",
    "df = pd.DataFrame({\n",
    "\"name\": [\"Bob\", \"Alex\", \"Janice\"],\n",
    "\"age\": [60, 25, 33]\n",
    "})\n",
    "# Reading a DataFrame from a file\n",
    "#other_df = pd.read_csv(“myfile.csv”)\n",
    "# Making new columns from old ones\n",
    "# is really easy\n",
    "df[\"age_plus_one\"] = df[\"age\"] + 1\n",
    "df[\"age_times_two\"] = 2 * df[\"age\"]\n",
    "#df[\"age_squared\"] = df[\"age\"] * df[\"age\"]\n",
    "df[\"over_30\"] = (df[\"age\"] > 30) # this col is bools\n",
    "# The columns have various built-in aggregate functions\n",
    "#3.6 Python’s Technical Libraries 39\n",
    "total_age = df[\"age\"].sum()\n",
    "median_age = df[\"age\"].quantile(0.5)\n",
    "# You can select several rows of the DataFrame\n",
    "# and make a new DataFrame out of them\n",
    "df_below50 = df[df[\"age\"] < 50]\n",
    "# Apply a custom function to a column\n",
    "df[\"age_squared\"] = df[\"age\"].apply(lambda x: x*x)\n",
    "print (df)\n",
    "print (total_age,median_age)\n",
    "\n",
    "print (df.index) # prints 0‐2, the line numbers\n",
    "# Create a DataFrame containing the same data,\n",
    "# but where name is the index\n",
    "df_w_name_as_ind = df.set_index(\"name\")\n",
    "print (df_w_name_as_ind.index) # prints their names\n",
    "# Get the row for Bob\n",
    "bobs_row = df_w_name_as_ind.ix[\"Bob\"]\n",
    "print (bobs_row[\"age\"]) # prints 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CH4\n",
    "\n",
    "def get_first_last_name(s):\n",
    "    INVALID_NAME_PARTS = [\"mr\", \"ms\", \"mrs\",\n",
    "                          \"dr\", \"jr\", \"sir\"]\n",
    "    parts = s.lower().replace(\".\",\"\").strip().split()\n",
    "    parts = [p for p in parts\n",
    "             if p not in INVALID_NAME_PARTS]\n",
    "    if len(parts)==0:\n",
    "        raise ValueError(\n",
    "                \"Name %s is formatted wrong\" % s)\n",
    "    first, last = parts[0], parts[-1]\n",
    "    first = first[0].upper() + first[1:]\n",
    "    last = last[0].upper() + last[1:]\n",
    "    return first, last\n",
    "\n",
    "def format_age(s):\n",
    "    chars = list(s) # list of characters\n",
    "    digit_chars = [c for c in chars if c.isdigit()]\n",
    "    return int(\"\".join(digit_chars))\n",
    "\n",
    "def format_date(s):\n",
    "    MONTH_MAP = {\n",
    "            \"jan\": \"01\", \"feb\": \"02\", \"may\": \"03\"}\n",
    "    s = s.strip().lower().replace(\",\", \"\")\n",
    "    m, d, y = s.split()\n",
    "    if len(y) == 2: y = \"19\" + y\n",
    "    if len(d) == 1: d = \"0\" + d\n",
    "    return y + \"-\" + MONTH_MAP[m[:3]] + \"-\" + d\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"file.tsv\", sep=\"|\")\n",
    "df[\"First Name\"] = df[\"Name\"].apply(\n",
    "        lambda s: get_first_last_name(s)[0])\n",
    "df[\"Last Name\"] = df[\"Name\"].apply(\n",
    "        lambda s: get_first_last_name(s)[1])\n",
    "df[\"Age\"] = df[\"Age\"].apply(format_age)\n",
    "df[\"Birthdate\"] = df[\"Birthdate\"].apply(\n",
    "        format_date).astype(pd.datetime)\n",
    "print df\n",
    "\n",
    "import re\n",
    "# This matches \"1600 Pennsylvania Ave.\"\n",
    "# It does NOT match \"5 Stony Brook St\"\n",
    "# cuz there is a space in \"Stony Brook\"\n",
    "street_pattern = r\"^[0-9]\\s[A-Z][a-z]*\" + \\\n",
    "r\"(Street|St|Rd|Road|Ave|Avenue|Blvd|Way|Wy)\\.?$\"\n",
    "# Like the one above, this assumes\n",
    "# there is no space in the town name\n",
    "city_pattern = r\"^[A-Z][a-z]*,\\s[A-Z]{2},[0-9]{5}$\"\n",
    "address_pattern = street_pattern + r\"\\n\" \\\n",
    "+ city_pattern\n",
    "# Compile the string into a regular expression object\n",
    "address_re = re.compile(address_pattern)\n",
    "text = open(\"some_file.txt\", \"r\").read()\n",
    "matches = re.findall(address_re, text)\n",
    "# list of all strings that match\n",
    "open(\"addresses_w_space_between.txt\",\n",
    "\"w\").write(\"\\n\\n\".join(matches))\n",
    "\n",
    "pattern = \"\\n\"\n",
    "my_re = re.compile(pattern) # trying to match a newline\n",
    "\n",
    "# Escape the slash w another\n",
    "slash_pattern = \"\\\\n\"\n",
    "# This matches a newline\n",
    "newline_re = re.compile(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CH5\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn.datasets\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "def get_iris_df():\n",
    "    ds = sklearn.datasets.load_iris()\n",
    "    df = pd.DataFrame(ds['data'],\n",
    "                      columns = ds['feature_names'])\n",
    "    code_species_map = dict(zip(\n",
    "            range(3), ds['target_names']))\n",
    "    df['species'] = [code_species_map[c]\n",
    "        for c in ds['target']]\n",
    "    return df\n",
    "\n",
    "df = get_iris_df()\n",
    "\n",
    "sums_by_species = df.groupby('species').sum()\n",
    "var = 'sepal width (cm)'\n",
    "sums_by_species[var].plot(kind='pie', fontsize=20)\n",
    "plt.ylabel(var, horizontalalignment='left')\n",
    "plt.title('Breakdown for ' + var, fontsize=25)\n",
    "#plt.savefig('iris_pie_for_one_variable.jpg')\n",
    "#plt.close()\n",
    "\n",
    "sums_by_species = df.groupby('species').sum()\n",
    "sums_by_species.plot(kind='pie', subplots=True,\n",
    "layout=(2,2), legend=False)\n",
    "plt.title('Total Measurements, by Species')\n",
    "#plt.savefig('iris_pie_for_each_variable.jpg')\n",
    "#plt.close()\n",
    "\n",
    "sums_by_species = df.groupby('species').sum()\n",
    "var = 'sepal width (cm)'\n",
    "sums_by_species[var].plot(kind='bar', fontsize=15,\n",
    "rot=30)\n",
    "plt.title('Breakdown for ' + var, fontsize=20)\n",
    "#plt.savefig('iris_bar_for_one_variable.jpg')\n",
    "#plt.close()\n",
    "\n",
    "sums_by_species = df.groupby('species').sum()\n",
    "sums_by_species.plot(\n",
    "kind='bar', subplots=True, fontsize=12)\n",
    "plt.suptitle('Total Measurements, by Species')\n",
    "#plt.savefig('iris_bar_for_each_variable.jpg')\n",
    "#plt.close()\n",
    "\n",
    "df.plot(kind='hist', subplots=True, layout=(2,2))\n",
    "plt.suptitle('Iris Histograms', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "for spec in df['species'].unique():\n",
    "    forspec = df[df['species']==spec]\n",
    "    forspec['petal length (cm)'].plot(\n",
    "            kind='hist', alpha=0.4, label=spec)\n",
    "plt.legend(loc='upper right')\n",
    "plt.suptitle('Petal Length by Species')\n",
    "plt.savefig('iris_hist_by_spec.jpg')\n",
    "\n",
    "col = df['petal length (cm)']\n",
    "Average = col.mean()\n",
    "Std = col.std()\n",
    "Median = col.quantile(0.5)\n",
    "Percentile25 = col.quantile(0.25)\n",
    "Percentile75 = col.quantile(0.75)\n",
    "\n",
    "col = df['petal length (cm)']\n",
    "Perc25 = col.quantile(0.25)\n",
    "Perc75 = col.quantile(0.75)\n",
    "Clean_Avg = col[(col>Perc25)&(col<Perc75)].mean()\n",
    "\n",
    "col = 'sepal length (cm)'\n",
    "df['ind'] = pd.Series(df.index).apply(lambda i: i% 50)\n",
    "df.pivot('ind','species')[col].plot(kind='box')\n",
    "plt.show()\n",
    "\n",
    "df.plot(kind=\"scatter\",\n",
    "x=\"sepal length (cm)\", y=\"sepal width (cm)\")\n",
    "plt.title(\"Length vs Width\")\n",
    "plt.show()\n",
    "\n",
    "#plt.close()\n",
    "colors = [\"r\", \"g\", \"b\"]\n",
    "markers= [\".\", \"*\", \"^\"]\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "for i, spec in enumerate(df['species'].unique() ):\n",
    "    ddf = df[df['species']==spec]\n",
    "    ddf.plot(kind=\"scatter\",\n",
    "             x=\"sepal width (cm)\", y=\"sepal length (cm)\",\n",
    "             alpha=0.5, s=10*(i+1), ax=ax,\n",
    "             color=colors[i], marker=markers[i], label=spec)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "df.plot(kind=\"hexbin\",\n",
    "x='sepal width (cm)', y='sepal length (cm)')\n",
    "plt.show()\n",
    "ds=sklearn.datasets\n",
    "bs = ds.load_boston()\n",
    "df = pd.DataFrame(bs.data, columns=bs.feature_names)\n",
    "df['MEDV'] = bs.target\n",
    "# Normal Scatterplot\n",
    "df.plot(x='CRIM',y='MEDV',kind='scatter')\n",
    "plt.title('Crime rate on normal axis')\n",
    "plt.show()\n",
    "\n",
    "df.plot(x='CRIM',y='MEDV',kind='scatter',logx=True)\n",
    "plt.title('Crime rate on logarithmic axis')\n",
    "plt.show()\n",
    "\n",
    "#plt.close()\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(df)\n",
    "plt.show()\n",
    "\n",
    "#plt.close()\n",
    "df.plot(kind=\"hexbin\",\n",
    "x='sepal width (cm)', y='sepal length (cm)')\n",
    "plt.show()\n",
    "\n",
    "dta = sm.datasets.co2.load_pandas().data\n",
    "dta.plot()\n",
    "plt.title(\"CO2 Levels\")\n",
    "plt.ylabel(\"Parts per million\")\n",
    "plt.show()\n",
    "\n",
    "URL = (\"http://ichart.finance.yahoo.com/\" +\n",
    "\"table.csv?s=GOOG&c=2000\")\n",
    "dat = urllib.urlopen(URL).read()\n",
    "open('foo.csv','w').write(dat)\n",
    "# Make DataFrame, w timestamp as the index\n",
    "df = pd.read_csv('foo.csv')\n",
    "df.index = df['Date'].astype('datetime64')\n",
    "df['LogClose'] = np.log(df['Close'])\n",
    "df['Close'].plot()\n",
    "plt.title(\"Normal Axis\")\n",
    "plt.show()\n",
    "df['Close'].plot(logy=True)\n",
    "plt.title(\"Logarithmic Axis\")\n",
    "plt.show()\n",
    "\n",
    "bs = ds.load_boston()\n",
    "df = pd.DataFrame(bs.data, columns=bs.feature_names)\n",
    "df['MEDV'] = bs.target\n",
    "# Normal Scatterplot\n",
    "df.plot(x='CRIM',y='MEDV',kind='scatter')\n",
    "plt.title('Crime rate on normal axis')\n",
    "plt.show()\n",
    "\n",
    "df.plot(x='CRIM',y='MEDV',kind='scatter',logx=True)\n",
    "plt.title('Crime rate on logarithmic axis')\n",
    "plt.show()\n",
    "\n",
    "#plt.close()\n",
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(df)\n",
    "plt.show()\n",
    "\n",
    "#plt.close()\n",
    "df.plot(kind=\"hexbin\",\n",
    "x='sepal width (cm)', y='sepal length (cm)')\n",
    "plt.show()\n",
    "\n",
    "dta = sm.datasets.co2.load_pandas().data\n",
    "dta.plot()\n",
    "plt.title(\"CO2 Levels\")\n",
    "plt.ylabel(\"Parts per million\")\n",
    "plt.show()\n",
    "\n",
    "URL = (\"http://ichart.finance.yahoo.com/\" +\n",
    "\"table.csv?s=GOOG&c=2000\")\n",
    "dat = urllib.urlopen(URL).read()\n",
    "open('foo.csv','w').write(dat)\n",
    "# Make DataFrame, w timestamp as the index\n",
    "df = pd.read_csv('foo.csv')\n",
    "df.index = df['Date'].astype('datetime64')\n",
    "df['LogClose'] = np.log(df['Close'])\n",
    "df['Close'].plot()\n",
    "plt.title(\"Normal Axis\")\n",
    "plt.show()\n",
    "df['Close'].plot(logy=True)\n",
    "plt.title(\"Logarithmic Axis\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
